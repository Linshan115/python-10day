from bs4 import BeautifulSoup     #网页解析，获取数据
import re       #正则表达式，进行文字匹配
import urllib.request,urllib.error      #制定url,获取网页数据
import xlwt     #进行excel操作
import sqlite3  #进行SQLite数据库操作


def main():
    
    Geturl(baseurl)







baseurl = "https://gaokao.chsi.com.cn/sch/search--ss-on,option-qg,searchType-1,start-"

findName = re.compile(r'<a href=".*">(.*)</a>',re.S)

def Askurl(url):
    head = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"
    }
    request = urllib.request.Request(url,headers=head)
    html = ""
    try:
        responce = urllib.request.urlopen(request)
        html = responce.read().decode("utf-8")
    except urllib.error.URLError as e:
        if hasattr(e,"code"):
            print(e.code)
        if hasattr(e,"reason"):
            print(e.reason)

    return html



def Geturl(url):
    datalist = []
    for i in range(0,141):
        url = baseurl + str(i*20)+".dhtml"
        html = Askurl(url)
        soup = BeautifulSoup(html, "html.parser")
        for item in soup.find_all('td', class_="js-yxk-yxmc"):
            data = []
            item = str(item)
            Name = re.findall(findName, item)
            if len(Name) !=0:
                Name = Name[0]
            else:
                Name = " "
            data.append(Name.strip())
            datalist.append(data)
    return datalist
    
    if __name__ == "__main__":      #当程序执行时
#调用函数
    main()
